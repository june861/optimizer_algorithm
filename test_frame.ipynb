{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pso.pso import PSO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "dim = 4\n",
    "p_num = 20\n",
    "x_min, x_max = -30, 30\n",
    "v_min, v_max = -60, 60\n",
    "\n",
    "PSO_Algorithm = PSO(C1 = 2, \n",
    "                    C2 = 2, \n",
    "                    Omega = 1,\n",
    "                    dim = dim,\n",
    "                    p_num = p_num, \n",
    "                    x_min = x_min, \n",
    "                    x_max = x_max, \n",
    "                    v_min = v_min, \n",
    "                    v_max = v_max\n",
    "                )\n",
    "for par in PSO_Algorithm.particles:\n",
    "    print(f'particle init pos is {par.get_pos()}')\n",
    "max_iter = 10000\n",
    "\n",
    "def cal_fitness(x):\n",
    "    return np.sum(x**2)\n",
    "    return sum(100.0 * (x[0][1:] - x[0][:-1] ** 2.0) ** 2.0 + (1 - x[0][:-1]) ** 2.0)\n",
    "\n",
    "for i in range(max_iter):\n",
    "    print(f'iter is {i+1}, fitness is {cal_fitness(PSO_Algorithm.g_best)}')\n",
    "    PSO_Algorithm.update(cal_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSO_Algorithm.g_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation   #导入负责绘制动画的接口\n",
    "#其中需要输入一个更新数据的函数来为fig提供新的绘图信息\n",
    "\n",
    "fig, ax = plt.subplots()          #生成轴和fig,  可迭代的对象\n",
    "x, y= [], []    #用于接受后更新的数据\n",
    "line, = plt.plot([], [], '.-')   #绘制线对象，plot返回值类型，要加逗号\n",
    "\n",
    "#------说明--------#\n",
    "#核心函数包含两个：\n",
    "#一个是用于初始化画布的函数init()\n",
    "#另一个是用于更新数据做动态显示的update()\n",
    "\n",
    "\n",
    "def init():\n",
    "\t#初始化函数用于绘制一块干净的画布，为后续绘图做准备\n",
    "    ax.set_xlim(-5, 15*np.pi)    #初始函数，设置绘图范围\n",
    "    ax.set_ylim(-3, 3)\n",
    "    return line\n",
    "\n",
    "def update(step):           #通过帧数来不断更新新的数值\n",
    "    x.append(step)\n",
    "    y.append(np.cos(step/3)+np.sin(step**2))    #计算y\n",
    "    line.set_data(x, y)\n",
    "    return line\n",
    "\n",
    "#fig 是绘图的画布\n",
    "#update 为更新绘图的函数，step数值是从frames 传入\n",
    "#frames 数值是用于动画每一帧的数据\n",
    "ani = FuncAnimation(fig, update, frames=np.linspace(0, 13*np.pi, 128),\n",
    "                    init_func=init,interval=20)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPO(object):\n",
    "    def __init__(self,state_dim, act_dim, hidden_dims,layer_nums,train_params) -> None:\n",
    "        self.ppo_params = {\n",
    "            # 网络层参数\n",
    "            'state_dim' : state_dim,\n",
    "            'act_dim' : act_dim,\n",
    "            'layer_nums' : layer_nums,\n",
    "\n",
    "            # 训练参数\n",
    "            'lr_a': train_params['lr_a'],\n",
    "            'lr_c': train_params['lr_c'],\n",
    "            'batch_size' : train_params['batch_size'],\n",
    "            'on_policy' : False,\n",
    "            'use_buffer' : False,\n",
    "            'use_tanh' : train_params['use_tanh']\n",
    "        }\n",
    "\n",
    "        if not isinstance(hidden_dims,list) :\n",
    "            raise RuntimeError(f\"hidden_dims type must be list, now receive {type(hidden_dims)}. \")\n",
    "        if len(hidden_dims) != layer_nums - 1:\n",
    "            raise RuntimeError(f\"hidden_dims'len expect {layer_nums-1}, but now receive {len(hidden_dims)}. \")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"my-awesome-project\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"architecture\": \"CNN\",\n",
    "    \"dataset\": \"CIFAR-100\",\n",
    "    \"epochs\": 10,\n",
    "    }\n",
    ")\n",
    "\n",
    "# simulate training\n",
    "epochs = 10\n",
    "offset = random.random() / 5\n",
    "for epoch in range(2, epochs):\n",
    "    acc = 1 - 2 ** -epoch - random.random() / epoch - offset\n",
    "    loss = 2 ** -epoch + random.random() / epoch + offset\n",
    "\n",
    "    # log metrics to wandb\n",
    "    wandb.log({\"acc\": acc, \"loss\": loss})\n",
    "\n",
    "# [optional] finish the wandb run, necessary in notebooks\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler\n",
    "for index in BatchSampler(range(1024), 64, False):\n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "# from share_func import make_env\n",
    "# train_envs = [ make_env(env_name = \"CartPole-v1\", seed = 1,idx = i,capture_video = False, run_name = f'_video{i}') for i in range(1000) ]\n",
    "def make_env(gym_id, seed, idx, capture_video, run_name):\n",
    "    def thunk():\n",
    "        env = gym.make(gym_id)\n",
    "        env = gym.wrappers.RecordEpisodeStatistics(env)\n",
    "        if capture_video:\n",
    "            if idx == 0:\n",
    "                env = gym.wrappers.RecordVideo(env, f\"videos/{run_name}\")\n",
    "        env.action_space.seed(seed)\n",
    "        env.observation_space.seed(seed)\n",
    "        return env\n",
    "\n",
    "    return thunk\n",
    "train_envs = [ make_env(gym_id = \"CartPole-v1\", seed = 1,idx = i,capture_video = False, run_name = f'_video{i}') for i in range(10) ]\n",
    "envs = gym.vector.SyncVectorEnv(train_envs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.make(\"CartPole-v1\")._max_episode_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "envs.single_action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env reset, state shape is (env_num, state_dim)\n",
    "from ppo.ppo import PPO\n",
    "import torch\n",
    "import numpy as np\n",
    "ppo_params = {\n",
    "        # ppo algorithm params\n",
    "        'clip_param' : 0.2,\n",
    "\n",
    "        # 训练参数\n",
    "        'lr_a': 1e-3,\n",
    "        'lr_c': 1e-3,\n",
    "        'gamma': 0.5,\n",
    "        'lamda': 0.5,\n",
    "        'batch_size' : 1024,\n",
    "        'mini_batch_size': 64,\n",
    "\n",
    "        # trick params\n",
    "\n",
    "        'off_policy' : False, # use off-policy or on-policy\n",
    "        'use_buffer' : True, # use buffer to store or not\n",
    "        \"use_ppo_clip\":False , # use ppo clip param annealing\n",
    "        \"use_adv_norm\" : True, # use advantage normalization\n",
    "        \"use_state_norm\" : False, # use state normalization\n",
    "        \"use_reward_norm\" : False, # use reward normalization\n",
    "        'use_tanh' : False, # use tanh activate func or ReLU func\n",
    "        'use_adv_norm' : False, # use advantage normalization\n",
    "        'use_grad_clip' : True, # use grad clip in model params.\n",
    "        'grad_clip_params': 0.5,\n",
    "        'use_lr_decay': True,\n",
    "        'entropy_coef': 0.1,\n",
    "        'device': torch.device(\"cuda\"),        \n",
    "}\n",
    "agent = PPO(state_dim = 4,act_dim = 2, hidden_dims = [64,64], layer_nums = 3, train_params = ppo_params)\n",
    "state, _ = envs.reset()\n",
    "done = np.full((10,1), False)\n",
    "while np.sum(done) == 0:\n",
    "    print(state, np.sum(done),sep=\"\\t\\t\")\n",
    "    action, a_logprob = agent.select_action(state)\n",
    "    state_, reward, done, truncation, _ = envs.step(action)\n",
    "    # replay_buffer.add(state = state, action = action, reward = reward, next_state = state_, a_logprob = a_logprob, done = done)\n",
    "    if np.sum(done) == envs.action_space.nvec.shape[0] :\n",
    "        print(f'done is {done}')\n",
    "        print(f'state shape is {state_.shape}, \\nstate is {state_}')\n",
    "    state = state_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    " \n",
    "cap = cv2.VideoCapture('XXX.avi')  #返回一个capture对象\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES,50)  #设置要获取的帧号\n",
    "a,b=cap.read()  #read方法返回一个布尔值和一个视频帧。若帧读取成功，则返回True\n",
    "cv2.imshow('b', b)\n",
    "cv2.waitKey(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "t1 = torch.Tensor(np.ones((2,5)))\n",
    "t2 = torch.Tensor(np.zeros((2,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([[1,2,3,4,5,6],[0,1,2,3,4,5]])\n",
    "b = torch.tensor([[5,4,3,2,1,0],[0,1,2,3,4,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a.gather(1,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6., 5., 4., 3., 2., 1.],\n",
       "        [0., 1., 2., 3., 4., 5.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([1., 2., 3., 4., 5., 6.]),\n",
       "indices=tensor([0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(a, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import ple\n",
    "from ple.games.catcher import Catcher\n",
    "from ple import PLE\n",
    "\n",
    "\n",
    "game = Catcher()\n",
    "p = PLE(game, fps=30, display_screen=True)\n",
    "\n",
    "p.init()\n",
    "reward = 0.0\n",
    "state = p.reset_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 48, 3) 0.0\n",
      "(64, 48, 3) 0.0\n",
      "(64, 48, 3) 0.0\n",
      "(64, 48, 3) 0.0\n",
      "(64, 48, 3) 0.0\n",
      "(64, 48, 3) 0.0\n",
      "(64, 48, 3) 0.0\n",
      "(64, 48, 3) 0.0\n",
      "(64, 48, 3) 0.0\n",
      "(64, 48, 3) 0.0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from ple.games.pong import Pong\n",
    "import numpy as np\n",
    "game = Pong()\n",
    "\n",
    "from ple import PLE\n",
    "\n",
    "p = PLE(game, fps=30, display_screen=True, force_fps=False)\n",
    "p.init()\n",
    "\n",
    "\n",
    "nb_frames = 10\n",
    "reward = 0.0\n",
    "\n",
    "for f in range(nb_frames):\n",
    "\tif p.game_over(): #check if the game is over\n",
    "\t\tp.reset_game()\n",
    "\n",
    "\tobs = p.getScreenRGB()\n",
    "\taction = 2\n",
    "\treward = p.act(action)\n",
    "\tdisplay_obs = np.array(obs)\n",
    "\tprint(display_obs.shape, reward, sep=\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                 Version      Editable project location\n",
      "----------------------- ------------ --------------------------------------\n",
      "absl-py                 2.1.0\n",
      "asttokens               2.0.5\n",
      "backcall                0.2.0\n",
      "box2d-py                2.3.8\n",
      "certifi                 2024.8.30\n",
      "charset-normalizer      3.3.2\n",
      "click                   8.1.7\n",
      "cloudpickle             3.0.0\n",
      "colorama                0.4.6\n",
      "comm                    0.2.1\n",
      "contourpy               1.3.0\n",
      "cycler                  0.12.1\n",
      "debugpy                 1.6.7\n",
      "decorator               5.1.1\n",
      "docker-pycreds          0.4.0\n",
      "exceptiongroup          1.2.0\n",
      "executing               0.8.3\n",
      "filelock                3.13.1\n",
      "fonttools               4.53.1\n",
      "fsspec                  2024.2.0\n",
      "gitdb                   4.0.11\n",
      "GitPython               3.1.43\n",
      "grpcio                  1.66.1\n",
      "gym                     0.26.2\n",
      "gym-notices             0.0.8\n",
      "idna                    3.8\n",
      "importlib_metadata      8.5.0\n",
      "importlib_resources     6.4.5\n",
      "ipykernel               6.28.0\n",
      "ipython                 8.15.0\n",
      "jedi                    0.19.1\n",
      "Jinja2                  3.1.3\n",
      "jupyter_client          8.6.0\n",
      "jupyter_core            5.7.2\n",
      "kiwisolver              1.4.7\n",
      "Markdown                3.7\n",
      "MarkupSafe              2.1.5\n",
      "matplotlib              3.9.2\n",
      "matplotlib-inline       0.1.6\n",
      "mpmath                  1.3.0\n",
      "nest-asyncio            1.6.0\n",
      "networkx                3.2.1\n",
      "numpy                   1.24.1\n",
      "opencv-python           4.10.0.84\n",
      "packaging               24.1\n",
      "pandas                  2.2.2\n",
      "parso                   0.8.3\n",
      "pickleshare             0.7.5\n",
      "pillow                  10.4.0\n",
      "pip                     24.2\n",
      "platformdirs            4.3.3\n",
      "ple                     0.0.1        f:\\library\\pygame-learning-environment\n",
      "prompt-toolkit          3.0.43\n",
      "protobuf                5.28.1\n",
      "psutil                  6.0.0\n",
      "pure-eval               0.2.2\n",
      "pygame                  2.1.0\n",
      "Pygments                2.15.1\n",
      "pyparsing               3.1.4\n",
      "python-dateutil         2.9.0.post0\n",
      "pytz                    2024.2\n",
      "pywin32                 305.1\n",
      "PyYAML                  6.0.2\n",
      "pyzmq                   25.1.2\n",
      "requests                2.32.3\n",
      "seaborn                 0.13.2\n",
      "sentry-sdk              2.14.0\n",
      "setproctitle            1.3.3\n",
      "setuptools              75.1.0\n",
      "six                     1.16.0\n",
      "smmap                   5.0.1\n",
      "stack-data              0.2.0\n",
      "sympy                   1.12\n",
      "tensorboard             2.17.1\n",
      "tensorboard-data-server 0.7.2\n",
      "torch                   2.4.1+cu118\n",
      "torch-tb-profiler       0.4.3\n",
      "torchaudio              2.4.1+cu118\n",
      "torchvision             0.19.1+cu118\n",
      "tornado                 6.4.1\n",
      "traitlets               5.14.3\n",
      "typing_extensions       4.11.0\n",
      "tzdata                  2024.1\n",
      "urllib3                 2.2.3\n",
      "wandb                   0.18.0\n",
      "wcwidth                 0.2.5\n",
      "Werkzeug                3.0.4\n",
      "wheel                   0.44.0\n",
      "zipp                    3.20.2\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
