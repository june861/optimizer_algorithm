[ENV]
env_name = Catcher,Pixelcopter,Pong,PuckWorld
env_num = 50
capacity = 10000

[MONITOR]
wandb = False
tensorboard = False

[NETWORK]
layers = 3
hidden_dims = 128,128

[DQN]
# the max iter of training
max_train_steps = 500
# the max steps in one game
max_eposide_step = 500
# the evaluation frequency
evaluate_freq = 10
# learning freqecny in one game
learn_freq = 10
# the evaluation times
evaluate_times = 10
# learning rate
dqn_lr = 0.001
# discounted parameter
gamma = 0.9
epsilon = 0.4
epsilon_min = 0.001
epsilon_decay = 0.0001
# batch size
batch_size = 4096
mini_batch_size = 256
# use lr decay trick
use_lr_decay = True
# the frequency to update target network
update_target = 200

[PPO]
use_multiprocess = False
per_batch_steps = 